{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a7f05c-b479-4714-a4a1-db66f3ebfb2d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning & GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750872e-3322-4fe5-b11d-16a654c3ce93",
   "metadata": {},
   "source": [
    "Welcome, This course covers the fundamentals of hyperparameter tuning, the mechanics of Cross-Validation, and practical implementation using `scikit-learn`'s `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22274a2-adbf-4712-ad83-b3e96c5c7a1b",
   "metadata": {},
   "source": [
    "## Module 1: Introduction to Hyperparameters\n",
    "* **1.1 Parameters vs. Hyperparameters:** Understanding the difference between model-learned parameters (e.g., weights in linear regression) and user-defined hyperparameters (e.g., learning rate, tree depth).\n",
    "* **1.2 The Need for Tuning:** How hyperparameters affect model performance (Underfitting vs. Overfitting).\n",
    "* **1.3 The Curse of Dimensionality in Tuning:** Why exhaustive search becomes computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629b0e30-05f9-43bb-bf04-6666709ed5d3",
   "metadata": {},
   "source": [
    "# Examples: Parameters vs Hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Linear Regression\n",
    "\n",
    "### Parameters:\n",
    "- The weights ($w_1, w_2, \\dots, w_n$)\n",
    "- The bias ($b$)\n",
    "\n",
    "The model calculates these automatically during training  \n",
    "(e.g., using **Ordinary Least Squares**).\n",
    "\n",
    "### Hyperparameters:\n",
    "- If using Gradient Descent â†’ the **Learning Rate ($\\alpha$)**  \n",
    "\n",
    "You must set this **before training begins**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Decision Trees\n",
    "\n",
    "### Parameters:\n",
    "- The actual decision rules at each node  \n",
    "  (e.g., *\"Is Age > 25?\"*, *\"Is Income < $50k?\"*)\n",
    "\n",
    "The model determines these splits based on the data.\n",
    "\n",
    "### Hyperparameters:\n",
    "- **Maximum Depth (`max_depth`)**\n",
    "\n",
    "You decide beforehand how deep the tree can grow  \n",
    "(e.g., maximum 5 levels).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40420365-8f39-4b64-bcd6-cdf6d996513d",
   "metadata": {},
   "source": [
    "![Underfitting vs Good Fit vs Overfitting](figure.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e735057-1b7f-4230-9a5b-5c9ef904e611",
   "metadata": {},
   "source": [
    "# Understanding Underfitting, Good Fit, and Overfitting\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‰ Left Side â€“ Underfitting (bad on both training and testing)\n",
    "\n",
    "- **Model is too simple**\n",
    "- **High bias**\n",
    "- **Poor performance** on training and testing data\n",
    "- **Example:** Linear model trying to fit complex data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Middle â€“ Good Fit (Optimal Model)\n",
    "\n",
    "- **Balanced bias and variance**\n",
    "- **Learns patterns properly**\n",
    "- **Performs well** on unseen data\n",
    "- **Best generalization**\n",
    "\n",
    "ğŸ’¡ *This is the goal of training.*\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ˆ Right Side â€“ Overfitting  (great on training, bad on testing)\n",
    "\n",
    "- **Model is too complex**\n",
    "- **Memorizes training data**\n",
    "- **High variance**\n",
    "- **Poor performance** on new data\n",
    "- **Example:** Deep neural network on small dataset\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18731661-f85a-419b-a6ad-853cc66cc70e",
   "metadata": {},
   "source": [
    "# 1.3 The Curse of Dimensionality in Hyperparameter Tuning\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ The Goal\n",
    "To understand **why we can't just try every possible hyperparameter** and why tuning can take a lot of time.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– The Core Concept\n",
    "**The Curse of Dimensionality** means:  \n",
    "> As you add more hyperparameters to tune, the number of combinations grows **exponentially**.  \n",
    "\n",
    "Checking every combination (brute force) **quickly becomes impossible**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ’¡ Analogy: The Combination Padlock\n",
    "- **1 dial (0-9):** 10 tries max  \n",
    "- **3 dials:** 10 Ã— 10 Ã— 10 = 1,000 tries  \n",
    "- **5 dials:** 10 Ã— 10 Ã— 10 Ã— 10 Ã— 10 = 100,000 tries  \n",
    "\n",
    "> Every new dial (hyperparameter) **multiplies the work**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Mathematical Example\n",
    "\n",
    "Suppose we tune a **Random Forest Classifier** with these options:\n",
    "\n",
    "| Hyperparameter | Options |\n",
    "|----------------|---------|\n",
    "| n_estimators | 10, 50, 100, 200, 500 (5 options) |\n",
    "| max_depth | None, 10, 20, 30 (4 options) |\n",
    "| min_samples_split | 2, 5, 10, 15, 20 (5 options) |\n",
    "\n",
    "\n",
    "**Total combinations:**  \n",
    "\n",
    "5 Ã— 4 Ã— 5  = 100 unique models\n",
    "\n",
    "\n",
    "Using **5-Fold Cross-Validation**:  \n",
    "\n",
    "\n",
    "100 combinations Ã— 5 folds = 500 model trainings\n",
    "\n",
    "\n",
    "\n",
    "If **1 model takes 1 minute**, the total time = **8.33 hours**!  \n",
    "Add one more hyperparameter with 10 options â†’ **83.3 hours (~3, 4 days)**!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f6132d3-c5b3-40bf-8307-7b7fb2881133",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 15, 20]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,              # 5-Fold Cross Validation\n",
    "    n_jobs=-1,         # Use all CPU cores\n",
    "    verbose=2          # Prints progress\n",
    ")\n",
    "\n",
    "# Fit the Grid Search to your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination found\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ce2c4-9dc8-4968-a8f3-c9199156f533",
   "metadata": {},
   "source": [
    "# Module 2: Cross-Validation (The Foundation)\n",
    "\n",
    "---\n",
    "\n",
    "## **2.1 What is Cross-Validation?**  \n",
    "Cross-validation is a technique to **evaluate how well your model will perform on unseen data**.  \n",
    "\n",
    "- The simple **train-test split** divides your dataset once into a training set and a test set.  \n",
    "- Problem: The modelâ€™s performance depends heavily on **which data ends up in the training vs test set**.  \n",
    "- **Cross-validation** solves this by **splitting the data multiple times** and averaging results for a more reliable estimate.  \n",
    "\n",
    "ğŸ’¡ *Analogy:* Testing a recipe multiple times on different groups of friends instead of relying on just one tasting session.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2.2 K-Fold Cross-Validation**  \n",
    "K-Fold Cross-Validation splits the dataset into **K equal parts (folds)**:\n",
    "\n",
    "1. Use **K-1 folds** to train the model.  \n",
    "2. Use the **remaining fold** to test the model.  \n",
    "3. Repeat this process **K times**, each time using a different fold as the test set.  \n",
    "4. Average the performance across all K runs â†’ **robust estimate of model performance**.  \n",
    "\n",
    "- Common choice: **K = 5 or 10**  \n",
    "- Pros: More reliable than a single train-test split, especially on small datasets  \n",
    "\n",
    "ğŸ’¡ *Example:* With 5-Fold CV, each fold is tested once â†’ 5 performance scores â†’ take the average.  \n",
    "\n",
    "---\n",
    "\n",
    "## **2.3 Stratified K-Fold**  \n",
    "- Sometimes datasets are **imbalanced** (e.g., 90% class A, 10% class B).  \n",
    "- Regular K-Fold may split data unevenly â†’ some folds might have very few minority class samples.  \n",
    "- **Stratified K-Fold** ensures **each fold preserves the class proportion** of the original dataset.  \n",
    "\n",
    "ğŸ’¡ *Analogy:* Think of making sure each tasting group gets a **balanced mix of cookie types** instead of ending up with only chocolate chip cookies in one group.  \n",
    "\n",
    "- In scikit-learn:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90244960-a582-4b0f-857a-14cbf7f0e50f",
   "metadata": {},
   "source": [
    "# Module 3: Introduction to GridSearchCV\n",
    "\n",
    "---\n",
    "\n",
    "## **3.1 The Grid Search Concept**\n",
    "\n",
    "**The Goal:**  \n",
    "You need to **visualize what a \"Grid\" means** in hyperparameter tuning. We are **systematically defining a finite set of values** to test.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“– Core Concept\n",
    "Grid Search is an **exhaustive search algorithm**:\n",
    "\n",
    "- You provide a list of hyperparameters and specific values to test.  \n",
    "- It builds a **mathematical grid** of all possible combinations.  \n",
    "- Each combination is evaluated to find the **best hyperparameters**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6c9f3-25aa-43da-be7b-e8ea44f27868",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Analogy: Restaurant Combo Meal\n",
    "Imagine building a combo meal:\n",
    "\n",
    "| Choice | Options | Number of options |\n",
    "|--------|--------|-----------------|\n",
    "| Main   | Burger, Chicken Sandwich, Veggie Wrap | 3 |\n",
    "| Side   | Fries, Salad | 2 |\n",
    "| Drink  | Soda, Water | 2 |\n",
    "\n",
    "- Total meals to try = 3 Ã— 2 Ã— 2 = **12 meals**  \n",
    "- A **Grid Search** is like trying **every possible combo** to find the best one.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ› ï¸ Technical Example (Random Forest)\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50],       # 2 options\n",
    "    'max_depth': [5, 10, None],     # 3 options\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ba5211-3895-4206-a5ba-099f986345c5",
   "metadata": {},
   "source": [
    "## 3.2 How GridSearchCV Works (Grid Search + K-Fold CV)\n",
    "\n",
    "**The Goal:**  \n",
    "Must understand that **each combination is evaluated rigorously using Cross-Validation**.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“– Core Concept\n",
    "**GridSearchCV = Grid Search + Cross-Validation**  \n",
    "\n",
    "- For **each hyperparameter combination**, it runs a **full K-Fold Cross-Validation**.  \n",
    "- The **best parameters** are the ones with the **highest average score** across all folds.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Analogy: Taste Test Panel\n",
    "- One person tasting all meals â†’ **biased opinion**.  \n",
    "- 5 judges tasting all meals â†’ **average score is fairer**.  \n",
    "- Similarly, **5-Fold CV evaluates each combination on multiple folds** to ensure reliability.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ› ï¸ Step-by-Step\n",
    "1. Pick **combination #1** from the grid.  \n",
    "2. Split the training data into **K folds**.  \n",
    "3. Train on **K-1 folds**, test on the remaining fold.  \n",
    "4. Repeat **K times** â†’ calculate **average score** for combination #1.  \n",
    "5. Repeat steps 1â€“4 for **all combinations**.  \n",
    "6. Compare all averages â†’ pick the **best combination**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c23a7cdd-0e18-4013-94c4-430088a096f5",
   "metadata": {},
   "source": [
    "START\n",
    "                      â”‚\n",
    "                      â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚   Define your   â”‚\n",
    "            â”‚   model &       â”‚\n",
    "            â”‚   parameters    â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â”‚\n",
    "                      â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚ Create a GRID   â”‚\n",
    "            â”‚ of all possible â”‚\n",
    "            â”‚ combinations    â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â”‚\n",
    "                      â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚                                  â”‚\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ Combination 1 â”‚                 â”‚ Combination 2   â”‚\n",
    "    â”‚ n_estimators=10â”‚                 â”‚ n_estimators=10 â”‚\n",
    "    â”‚ max_depth=3   â”‚                 â”‚ max_depth=5     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚                                  â”‚\n",
    "            â–¼                                  â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ CROSS-VALIDATEâ”‚                  â”‚ CROSS-VALIDATEâ”‚\n",
    "    â”‚               â”‚                  â”‚               â”‚\n",
    "    â”‚ Fold 1: 85%   â”‚                  â”‚ Fold 1: 86%   â”‚\n",
    "    â”‚ Fold 2: 84%   â”‚                  â”‚ Fold 2: 87%   â”‚\n",
    "    â”‚ Fold 3: 86%   â”‚                  â”‚ Fold 3: 88%   â”‚\n",
    "    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€      â”‚                  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€      â”‚\n",
    "    â”‚ AVG: 85%      â”‚                  â”‚ AVG: 87%      â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚                                  â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚      Compare ALL results         â”‚\n",
    "            â”‚                                  â”‚\n",
    "            â”‚  Combo 1: 85%  â”‚  Combo 5: 89%   â”‚\n",
    "            â”‚  Combo 2: 87%  â”‚  Combo 6: 91%   â”‚\n",
    "            â”‚  Combo 3: 86%  â”‚  Combo 7: 90%   â”‚\n",
    "            â”‚  Combo 4: 88%  â”‚  Combo 8: 88%   â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚      ğŸ† PICK THE BEST!           â”‚\n",
    "            â”‚   Best combo: Combo 6 (91%)      â”‚\n",
    "            â”‚   Best params:                   â”‚\n",
    "            â”‚   n_estimators=50, max_depth=5   â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â–¼\n",
    "                         FINISH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa554bee-ea8b-45f8-a9b5-98b789ea5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1019909d-d0e5-49d4-ba56-524bfca13b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5420caea-e7ed-4a31-a537-17a057b65925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "       [ 0.,  0., 10., ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fcb2e6-e4f5-46c3-802c-ebbb0aa7ffb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50dd5bd2-87ec-474c-ac31-4e672e8d051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = digits.data, digits.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27e831ed-5504-4319-aa9a-7afc589598be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 36 candidates, totalling 252 fits\n",
      "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best Cross-Validation Score: 0.9784208923920029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion':['gini','entropy']\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=7,              # 5-Fold Cross Validation\n",
    "    n_jobs=-1,         # Use all CPU cores\n",
    "    verbose=2          # Prints progress\n",
    ")\n",
    "\n",
    "# Fit the Grid Search to your training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best combination found\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d5ecddd-e5ad-4095-aafa-46fdb819ea64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score on test data:  0.9992930613967651\n",
      "[[0.06       0.01016949 0.         ... 0.01       0.         0.29811905]\n",
      " [0.         0.05       0.79714286 ... 0.         0.02285714 0.01      ]\n",
      " [0.01       0.2        0.03       ... 0.06       0.58496855 0.02037736]\n",
      " ...\n",
      " [0.99       0.         0.         ... 0.01       0.         0.        ]\n",
      " [0.         0.02090909 0.05194805 ... 0.         0.01500866 0.01252291]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred = grid_search.predict(X_test)\n",
    "y_pred_proba = grid_search.predict_proba(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "print(\"ROC AUC Score on test data: \", roc_auc)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b9b11-d2dc-48d8-be99-322790f6dacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
